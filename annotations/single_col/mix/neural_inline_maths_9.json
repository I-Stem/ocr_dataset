{"multicolumn": false, "figures": [["0.564705", "0.592945", "0.400121", "0.174233"]], "tables": [[["0.503427", "0.251150", "0.848015", "0.336350"], ",(3a) Macro average.,NaN,NaN,NaN\n0,Method,Precision,Recall,F-measure\n1,InftyReader (Eto and Suzuki (2001)),0.138,0.867,0.238\n2,CRF1 (Iwatsuki et al. (2017)),0.865,0.75,0.804\n3,Bi-LSTM-CRF (Huang et al. (2015)),0.85,0.701,0.762\n4,Bi-LSTM-CRF + features,0.885,0.763,0.816\n5,CRF2,0.878,0.8,0.834\n6,BIMExD,0.853,0.826,0.839\n7,HIMExD,0.889,0.836,0.861\n8,(3b) Micro average.,,,\n9,Method,Precision,Recall,F-measure\n10,InftyReader (Eto and Suzuki (2001)),0.13,0.899,0.228\n11,CRF1 (Iwatsuki et al. (2017)),0.949,0.836,0.889\n12,Bi-LSTM-CRF (Huang et al. (2015)),0.984,0.985,0.985\n13,Bi-LSTM-CRF + features,0.987,0.986,0.987\n14,CRF2,0.987,0.991,0.988\n15,BIMExD,0.99,0.99,0.99\n16,HIMExD,0.99,0.991,0.99\n"]], "text": "MADISETTY ET AL . Expert Systems WILEY 9 Note: The first three models are from literature, whereas the remaining ones are proposed in this paper. CRF2 is our feature-based approach, BIMExD & HIMExD are our proposed deep learning based approaches. Bi-LSTM-CRF + Features are built on top of existing Bi-LSTM-CRF architecture. Best results are put in bold. FIGURE 5 Macro average comparison successful impact of deep learning models (as they capture a representation of important features efficiently). Bar charts comparing all the base- line and proposed methods for macro average and micro average are shown in Figures 5 and 6 respectively. We can observe that our proposed method F-Measure is performing better than all other baseline approaches. As we aim to achieve better evaluation results for minor classes (B-Math and I-Math), in this section, we will discuss the scores of each class in detail. The top three methods which are performed best according to the F-Measure (as described in Table 3) are analysed further. The class- specific performance evaluation of different models is shown in Table 4. Results of the Conditional Random Fields (CRF2) model are shown in Table 4. For all the evaluation metrics (precision, recall, f-measure) the score for O-Math class is around 99% which is expected because O-Math class has large number of training instances. For both B-Math and I-math classes, precision is better than recall. F-measure is better for the I-Math class compared to the B-Math class. BIMExD results are shown in Table 5. The performance behaviour for the O-Math class in this method is sim- ilar to the behaviour for the O-Math class in the CRF method. Precision is better than recall for both B-Math and I-Math classes. In BIMExD, F- Measure for the I-Math class is higher compared to the B-Math class. ","maths":[]}